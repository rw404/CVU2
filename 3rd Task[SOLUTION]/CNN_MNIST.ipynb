{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c9f7b8-bce8-4f4e-a249-ec939206c8dd",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9a22c4-0e4a-47a8-84b5-73e30816e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750d8e7-ea6f-4743-ab88-a7845dc71da3",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Загрузим данные и посмотрим на их количество\n",
    "- В файле **Mnist_X.npy** изображения, в **Mnist_y.npy** - ответы;\n",
    "- Для тренировки используем первые **60000** экземпляров, для теста -- **10000**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f713dd-c55b-418a-a337-0a08650ad333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('../SimpleNet/Mnist_X.npy')\n",
    "y = np.load('../SimpleNet/Mnist_y.npy')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdeb499e-95ef-4c92-ae16-9b37e772e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X = X[:60000], X[60000:]\n",
    "train_y, test_y = y[:60000], y[60000:]\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b3e4b-93de-46fb-99d3-d9b76922e9a0",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Создадим класс с данными, который будет реалзовывать все необходимые для обучения сети методы:\n",
    "- Начальная инициализация:\n",
    "    - Задаем режим, для которого эти данные выбираются: **тренировка train**, **валидация val**, **тестирование test**;\n",
    "    - Равномерное деление на валидацию и тестирование: создадим словарь, в котором будем хранить кол-во представителей каждого класса. Когда добавляем элемент, увеличиваем соответствующий счетчик;\n",
    "    - Задаем параметр деления выборки(в каком соотношении на тренировочную и валидационную). \n",
    "- Вернуть длину выборки датасета\n",
    "- Получить элемент из выбоки:\n",
    "    - Изображение (28 на 28 пикселей) представить в виде одного вектора длины 784\n",
    "    - Представить вектор в тип данных для torch и вернуть пару (вектор и метка класса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a87532-4847-4a12-9c7b-50496eba000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 mode,\n",
    "                 X,\n",
    "                 y,\n",
    "                 fraction: float = 0.8,\n",
    "                ):\n",
    "        ## list of tuples: (img, label)\n",
    "        self._items = []\n",
    "        train_len = fraction*X.shape[0]\n",
    "        class_cnt = {i: 0 for i in range(10)}\n",
    "        class_len = train_len//10\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        if mode == 'train' or mode == 'val':\n",
    "            for i in range(X.shape[0]):\n",
    "                if len(self._items) < train_len and class_cnt[y[i]] < class_len:\n",
    "                    if mode == 'train':\n",
    "                        self._items.append((X[i], y[i]))\n",
    "                    class_cnt[y[i]] += 1\n",
    "                else:\n",
    "                    if mode == 'val':\n",
    "                        self._items.append((X[i], y[i]))\n",
    "                    \n",
    "        else:\n",
    "            self._items = list(zip(X, y))\n",
    "        np.random.shuffle(self._items)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._items)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self._items[index]\n",
    "\n",
    "        img = np.stack([img], axis=2)\n",
    "        img = torch.from_numpy(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0a175c-b18a-48f5-aa23-5d1691d8690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MyCustomDataset('train', train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27af2e1-8af4-4615-ae93-73ec7a144f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = MyCustomDataset('val', train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45627d5f-aa83-44d6-8827-40e1e2211111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = MyCustomDataset('test', test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566afe64-2f0a-486c-9a47-bec112ecd3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 12000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8595cd-d885-4049-b403-b9012bd39a8b",
   "metadata": {},
   "source": [
    "## Пример\n",
    "\n",
    "Покажем, как из данных датасета получить изображение и его метку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94ed23f-1dc6-4ead-9db7-afac79cfb4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Цифра 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im, label = ds_train[0]\n",
    "im = im.detach().cpu().numpy()\n",
    "plt.imshow(im)\n",
    "print(f'Цифра {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21895ea8-5bab-45d0-b4a3-5a4def563fa9",
   "metadata": {},
   "source": [
    "## Упаковываем данные в батчи, которые будут поступать на вход сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d196048-2fb4-449d-a18e-8f53bd046317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "dl_val = DataLoader(ds_val, batch_size=32, shuffle=False, num_workers=0)\n",
    "dl_test = DataLoader(ds_test, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8cd1a-67c2-478c-9779-a026999999c8",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6f2827-d0f2-464c-a05c-5e68568f52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    # REQUIRED\n",
    "    def __init__(self, input_shape=(3, 130, 130), test_data=dl_test, num_classes=10, freeze=True):\n",
    "        super().__init__()\n",
    "        \"\"\" Define computations here. \"\"\"\n",
    "        \n",
    "        # Описываем модель\n",
    "        # Два сверточных блока\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, padding=2)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Полносвязный слой\n",
    "        self.fc1 = nn.Linear(32*7*7, 100)\n",
    "        self.act3 = nn.LeakyReLU(0.1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "        # Для оценки качества на тестовых данных можем указать \n",
    "        # сразу данные, на которых и будет производиться эта оценка\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        # В качестве ошибки выступает кросс-энтропия\n",
    "        self.loss = F.cross_entropy\n",
    "        \n",
    "        # Дополнительно посмотрим на метрику точности, т.к. она более понятна\n",
    "        self.accuracy = lambda x, y: (x.argmax(-1) == y).float().mean()\n",
    "    \n",
    "    # REQUIRED\n",
    "    def forward(self, x):\n",
    "        \"\"\" Use for inference only (separate from training_step). \"\"\"\n",
    "        # Чтобы избежать ошибок, переводим данные в нужный формат\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Описываем поведение сети, т.е. как она проходит \n",
    "        # через 1-ый слой свертки, \n",
    "        x = self.norm1(self.pool1(self.act1(self.conv1(x))))\n",
    "        # 2-ой слой свертки\n",
    "        x = self.norm2(self.pool2(self.act2(self.conv2(x))))\n",
    "        # переход к полносвязным слоям\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop1(self.act3(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    # REQUIRED -- в конце каждого этапа обучения будут сохраняться результаты \n",
    "    # ошибок и точности на данной эпохе для обуающей выборки\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"the full training loop\"\"\"\n",
    "        x, y = batch\n",
    "        \n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "\n",
    "        y_logit = self(x)\n",
    "        loss = self.loss(y_logit, y)\n",
    "        \n",
    "        acc = self.accuracy(y_logit, y)\n",
    "\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "\n",
    "    # REQUIRED -- определяем оптимизатор и задаем learning rate\n",
    "    # P.s. еще можно указать как менять скорость обучения, \n",
    "    #      но тут мало эпох и слишком простая задача для этого\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Define optimizers and LR schedulers. \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    # OPTIONAL -- как и с обучающими, но тут результаты на валидации, чтобы отслеживать переобучение\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"the full validation loop\"\"\"\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "            \n",
    "        y_logit = self(x)\n",
    "        loss = self.loss(y_logit, y)\n",
    "        \n",
    "        acc = self.accuracy(y_logit, y)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    # OPTIONAL -- как раз визуализация среднего значения результатов на обучающей выборке\n",
    "    def training_epoch_end(self, outputs):\n",
    "        \"\"\"log and display average train loss and accuracy across epoch\"\"\"\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        \n",
    "        print(f\"| Train_acc: {avg_acc:.2f}, Train_loss: {avg_loss:.2f}\" )\n",
    "        \n",
    "        self.log('train_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('train_acc', avg_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "     \n",
    "    # OPTIONAL -- то же самое для валидации\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"log and display average val loss and accuracy\"\"\"\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        \n",
    "        print(f\"[Epoch {self.trainer.current_epoch:3}] Val_loss: {avg_loss:.5f} Val_accuracy: {avg_acc:.5f}\", end= \" \")\n",
    "        \n",
    "        self.log('val_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('val_acc', avg_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "    \n",
    "    # Оценка качества на тестовой выборке\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        x = x.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        \n",
    "    # Какие данные сеть полагает тестовыми\n",
    "    def test_dataloader(self):\n",
    "        return self.test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093c0fc-4e2c-4977-8faa-e737e8e50e98",
   "metadata": {},
   "source": [
    "# Обучение\n",
    "\n",
    "1. Создаем модель\n",
    "2. Задаем \"учителя\"\n",
    "3. Запускаем процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2531942-c4dd-4579-9443-ee96c11731a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (act1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (act2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=1568, out_features=100, bias=True)\n",
      "  (act3): LeakyReLU(negative_slope=0.1)\n",
      "  (drop1): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = MyModel()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "743ed944-7799-4eb1-9236-b7df16ebceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    gpus=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47fd5d2f-dd94-415f-9144-381162f09a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name  | Type        | Params\n",
      "---------------------------------------\n",
      "0  | conv1 | Conv2d      | 416   \n",
      "1  | act1  | ReLU        | 0     \n",
      "2  | pool1 | MaxPool2d   | 0     \n",
      "3  | norm1 | BatchNorm2d | 32    \n",
      "4  | conv2 | Conv2d      | 12.8 K\n",
      "5  | act2  | ReLU        | 0     \n",
      "6  | pool2 | MaxPool2d   | 0     \n",
      "7  | norm2 | BatchNorm2d | 64    \n",
      "8  | fc1   | Linear      | 156 K \n",
      "9  | act3  | LeakyReLU   | 0     \n",
      "10 | drop1 | Dropout     | 0     \n",
      "11 | fc2   | Linear      | 1.0 K \n",
      "---------------------------------------\n",
      "171 K     Trainable params\n",
      "0         Non-trainable params\n",
      "171 K     Total params\n",
      "0.685     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] Val_loss: 5.86109 Val_accuracy: 0.09375 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da5f0ee93c420597fa44e0f5f31723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train_acc: 0.95, Train_loss: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] Val_loss: 0.08065 Val_accuracy: 0.97658 | Train_acc: 0.98, Train_loss: 0.08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] Val_loss: 0.06855 Val_accuracy: 0.98225 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(m, dl_train, dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3299f-f3d2-4244-8790-6461def9e162",
   "metadata": {},
   "source": [
    "# Результаты на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99a6431-f240-46b0-b2db-771369545a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94417221e6a140ada0639f4ed8d5b9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9821000099182129, 'test_loss': 0.0639115571975708}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0639115571975708, 'test_acc': 0.9821000099182129}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
